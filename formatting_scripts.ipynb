{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various functions for formatting the data, and other relevant data formatting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract images from the dataset and copy it to the new folder\n",
    "\n",
    "Used to run CSEC image correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "input_folder = \"/home/dasec-notebook/Thesis/Datasets/mst-e_data/FIQA_CSEC\"  # Replace with the path to your folder of folders\n",
    "output_folder = \"/home/dasec-notebook/Thesis/Datasets/mst-e_data/FIQA_CSEC_extracted/\"  # Replace with the path to your new folder\n",
    "\n",
    "\n",
    "# If no valid extensions are provided, default to common image extensions\n",
    "valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp', '.JPG']\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Walk through the input folder and process each subfolder\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in valid_extensions):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(root, file)\n",
    "            dest_path = os.path.join(output_folder, file)\n",
    "            \n",
    "            counter = 1\n",
    "            while os.path.exists(dest_path):\n",
    "                name, ext = os.path.splitext(file)\n",
    "                dest_path = os.path.join(output_folder, f\"{name}_{counter}{ext}\")\n",
    "                counter += 1\n",
    "            \n",
    "            # Copy the file to the new directory\n",
    "            shutil.copy(file_path, dest_path)\n",
    "            print(f\"Copied: {file_path} -> {dest_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the folder stucture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths to the directories\n",
    "# extracted_folder = \"/home/dasec-notebook/Thesis/Datasets/CHROMA-FIT-Dataset/old/CSEC_extracted/\"  # Directory with extracted files\n",
    "# original_folder = \"/home/dasec-notebook/Thesis/Datasets/CHROMA-FIT-Dataset/DATA_CROPPED_PORTRAIT2/\"  # Original folder with folder structure\n",
    "# output_folder = \"/home/dasec-notebook/Thesis/Datasets/CHROMA-FIT-Dataset/CSEC/\"  # New folder to add extracted files back\n",
    "\n",
    "extracted_folder = \"/home/dasec-notebook/Thesis/Datasets/mst-e_data/old/CSEC_extracted/\"  # Directory with extracted files\n",
    "original_folder = \"/home/dasec-notebook/Thesis/Datasets/mst-e_data/mst-e_data_portrait/\"  # Original folder with folder structure\n",
    "output_folder = \"/home/dasec-notebook/Thesis/Datasets/mst-e_data/CSEC/\"  # New folder to add extracted files back\n",
    "\n",
    "\n",
    "valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp', '.JPG']\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Walk through the original folder to replicate its structure in the output folder\n",
    "for root, dirs, files in os.walk(original_folder):\n",
    "    for dir_name in dirs:\n",
    "        original_dir_path = os.path.join(root, dir_name)\n",
    "        relative_path = os.path.relpath(original_dir_path, original_folder)\n",
    "        new_dir_path = os.path.join(output_folder, relative_path)\n",
    "\n",
    "        if not os.path.exists(new_dir_path):\n",
    "            os.makedirs(new_dir_path)\n",
    "\n",
    "# Add extracted images to their corresponding folders\n",
    "for file_name in os.listdir(extracted_folder):\n",
    "    if any(file_name.lower().endswith(ext) for ext in valid_extensions):\n",
    "        found = False\n",
    "        for root, dirs, files in os.walk(original_folder):\n",
    "            if file_name in files:\n",
    "                relative_path = os.path.relpath(root, original_folder)\n",
    "                dest_dir = os.path.join(output_folder, relative_path)\n",
    "                dest_path = os.path.join(dest_dir, file_name)\n",
    "\n",
    "                # Copy the file to the corresponding folder\n",
    "                shutil.copy(os.path.join(extracted_folder, file_name), dest_path)\n",
    "                # print(f\"Copied: {file_name} -> {dest_path}\")\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            print(f\"Warning: {file_name} not found in original folder structure. Skipping.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare 2 directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_files_with_relative_paths(root_folder):\n",
    "    \"\"\"\n",
    "    Walk through the folder structure and return a set of all files with their relative paths.\n",
    "    \"\"\"\n",
    "    file_set = set()\n",
    "    for root, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            # Get the relative path of each file\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), root_folder)\n",
    "            file_set.add(relative_path)\n",
    "    return file_set\n",
    "\n",
    "def compare_directories(root1, root2):\n",
    "    \"\"\"\n",
    "    Compare two root directories and print out the differences.\n",
    "    \"\"\"\n",
    "    # Get all files with relative paths for both directories\n",
    "    files1 = get_files_with_relative_paths(root1)\n",
    "    files2 = get_files_with_relative_paths(root2)\n",
    "\n",
    "    only_in_root1 = files1 - files2\n",
    "    only_in_root2 = files2 - files1\n",
    "\n",
    "    # Print results\n",
    "    if only_in_root1:\n",
    "        print(f\"Files only in {root1}:\")\n",
    "        for file in sorted(only_in_root1):\n",
    "            print(f\"  {file}\")\n",
    "\n",
    "    if only_in_root2:\n",
    "        print(f\"Files only in {root2}:\")\n",
    "        for file in sorted(only_in_root2):\n",
    "            print(f\"  {file}\")\n",
    "\n",
    "    if not only_in_root1 and not only_in_root2:\n",
    "        print(\"The directories contain the same files.\")\n",
    "\n",
    "root_folder_1 = \"/home/dasec-notebook/Thesis/Datasets/CHROMA-FIT-Dataset/DATA_CROPPED_PORTRAIT2\" \n",
    "root_folder_2 = \"/home/dasec-notebook/Thesis/Datasets/CHROMA-FIT-Dataset/CSEC\" \n",
    "compare_directories(root_folder_1, root_folder_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWATCHES_MAPPING = {\n",
    "    1: [246, 237, 228],\n",
    "    2: [243, 231, 219],\n",
    "    3: [247, 234, 208],\n",
    "    4: [234, 218, 186],\n",
    "    5: [215, 189, 150],\n",
    "    6: [160, 126, 86],\n",
    "    7: [130, 92, 67],\n",
    "    8: [96, 65, 52],\n",
    "    9: [58, 49, 42],\n",
    "    10: [41, 36, 32]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "predicted_folder = \"/home/dasec-notebook/Thesis/skin_tone_estimation/baseline/results/predicted_MST\"\n",
    "\n",
    "# predicted = \"/home/dasec-notebook/Thesis/skin_tone_estimation/baseline/results/predicted_MST/CHROMA-FIT.csv\"\n",
    "ground_truth = \"/home/dasec-notebook/Thesis/skin_tone_estimation/image_paths/ground_truth_CHROMA-FIT_forehead.csv\"\n",
    "save_path = \"/home/dasec-notebook/Thesis/visualization/confusion_matrix/computer_vision\"\n",
    "\n",
    "ground_truth = pd.read_csv(ground_truth)\n",
    "\n",
    "# generate full paths\n",
    "files = os.listdir(predicted_folder)\n",
    "files = [os.path.join(predicted_folder, file) for file in files]\n",
    "\n",
    "for predicted in files:\n",
    "\n",
    "    save_name = os.path.basename(predicted).split(\".\")[0]\n",
    "    print(save_name)\n",
    "\n",
    "    predicted_data = pd.read_csv(predicted)\n",
    "\n",
    "    merged_data = ground_truth.merge(predicted_data, left_on=\"ID\", right_on=\"ID\", how=\"inner\")\n",
    "    true_labels = merged_data[\"Ground_Truth_Avg\"]\n",
    "    predicted_labels = merged_data[\"Best_MST_Orb\"]\n",
    "    plt.clf()\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=range(1, 10), normalize=\"true\")\n",
    "    conf_matrix = np.round(conf_matrix, 2)  # Round to 2 decimal places\n",
    "\n",
    "    display_labels = [str(i) for i in range(1, 10)]  # Adjust this according to your labels\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=display_labels)\n",
    "    disp.plot(cmap=\"Purples\")\n",
    "    # plt.title(\"Confusion Matrix: Ground Truth vs Predicted MST\")\n",
    "    plt.savefig(os.path.join(save_path, f\"{save_name}_normalize.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=range(1, 10))\n",
    "    conf_matrix = np.round(conf_matrix, 2)  # Round to 2 decimal places\n",
    "\n",
    "    display_labels = [str(i) for i in range(1, 10)]  # Adjust this according to your labels\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=display_labels)\n",
    "    disp.plot(cmap=\"Purples\")\n",
    "    # plt.title(\"Confusion Matrix: Ground Truth vs Predicted MST\")\n",
    "    plt.savefig(os.path.join(save_path, f\"{save_name}.png\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the weighted F1 score from txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "# Path to the directory containing the text files\n",
    "directory = \"/home/dasec-notebook/Thesis/skin_tone_estimation/multiclass_classification/results/results_v2.7\"\n",
    "\n",
    "# List of files in the desired order\n",
    "file_list = [\n",
    "    \"CHROMA_FIT_data.txt\",\n",
    "    \"CHROMA_FIT_CSEC_data.txt\",\n",
    "    \"CHROMA_FIT_exposure_color_correction_data.txt\",\n",
    "    \"CHROMA_FIT_CSEC_data_original.txt\",\n",
    "    \"CHROMA_FIT_exposure_color_correction_data_original.txt\",\n",
    "    \"CHROMA_FIT_data_MST_original.txt\",\n",
    "    \"CHROMA_FIT_CSEC_data_MST.txt\",\n",
    "    \"CHROMA_FIT_exposure_color_correction_data_MST.txt\",\n",
    "    \"CHROMA_FIT_CSEC_data_MST_original.txt\",\n",
    "    \"CHROMA_FIT_exposure_color_correction_data_MST_original.txt\"\n",
    "]\n",
    "\n",
    "# Regex pattern to match all weighted average F1-scores\n",
    "weighted_f1_pattern = r\"weighted avg\\s+\\d+\\.\\d+\\s+\\d+\\.\\d+\\s+(\\d+\\.\\d+)\"\n",
    "\n",
    "# Iterate through all .txt files in the directory\n",
    "for filename in file_list:\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "            matches = re.findall(weighted_f1_pattern, content)\n",
    "            \n",
    "            if matches:\n",
    "                print(f\"File: {filename}\")\n",
    "                for i, match in enumerate(matches, start=1):\n",
    "                    # print(f\"  Weighted Avg F1-Score {i}: {float(match)}\")\n",
    "                    print(float(match))\n",
    "                print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "\n",
    "def crop_to_same_aspect_ratio(folder_path, output_folder, target_aspect_ratio):\n",
    "    \"\"\"\n",
    "    Crop images to the same aspect ratio without distorting them.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing images.\n",
    "        output_folder (str): Path to save the cropped images.\n",
    "        target_aspect_ratio (tuple): Target aspect ratio as (width, height).\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get all image file paths in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'tiff'))]\n",
    "\n",
    "    # Calculate the target aspect ratio\n",
    "    target_width, target_height = target_aspect_ratio\n",
    "    target_ratio = target_width / target_height\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            current_ratio = width / height\n",
    "\n",
    "            if current_ratio > target_ratio:\n",
    "                # Image is wider than target aspect ratio; crop width\n",
    "                new_width = int(height * target_ratio)\n",
    "                left = (width - new_width) // 2\n",
    "                right = left + new_width\n",
    "                top = 0\n",
    "                bottom = height\n",
    "            else:\n",
    "                # Image is taller than target aspect ratio; crop height\n",
    "                new_height = int(width / target_ratio)\n",
    "                top = (height - new_height) // 2\n",
    "                bottom = top + new_height\n",
    "                left = 0\n",
    "                right = width\n",
    "\n",
    "            # Crop the image\n",
    "            cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "            output_path = os.path.join(output_folder, image_file)\n",
    "            cropped_img.save(output_path)\n",
    "            print(f\"Cropped and saved: {output_path}\")\n",
    "\n",
    "# Define folder paths\n",
    "input_folder = \"/home/dasec-notebook/Thesis/visualization/Cheek patches segmentation/original\"\n",
    "output_folder = \"/home/dasec-notebook/Thesis/visualization/Cheek patches segmentation/original_cropped\"\n",
    "\n",
    "target_aspect_ratio = (13,16)\n",
    "\n",
    "# Run the function\n",
    "crop_to_same_aspect_ratio(input_folder, output_folder, target_aspect_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSEC bias analysis, skin tone distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MST_swatches = {\n",
    "    1: '#f6ede4',\n",
    "    2: '#f3e7db',\n",
    "    3: '#f7ead0',\n",
    "    4: '#eadaba',\n",
    "    5: '#d7b496',\n",
    "    6: '#a07e56',\n",
    "    7: '#825c43',\n",
    "    8: '#604134',\n",
    "    9: '#3a312a',\n",
    "    10: '#292420'\n",
    "}\n",
    "# Load the CSV file\n",
    "data = pd.read_csv(\"/home/dasec-notebook/Thesis/skin_tone_estimation/baseline/results/predicted_MST/MST_CSEC.csv\") \n",
    "\n",
    "# Count the occurrences of each MST category in Best_MST_Orb\n",
    "mst_counts = data['Best_MST_Orb'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "bar_colors = mst_counts.index.map(MST_swatches)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "mst_counts.plot(kind='bar', color=bar_colors, edgecolor='black')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('MST Category')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "# plt.title('Distribution of Best MST Orb')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = \"/home/dasec-notebook/Thesis/skin_tone_estimation/multiclass_classification/training_data/v2/CHROMA-FIT_exposure_color_correction_data.json\"\n",
    "indices_to_extract = [11,14,20,31,50,53,64,71,81,82,91,97,103,112,129,131,136,173,181,186,196,202,226,247,262,272]\n",
    "\n",
    "\n",
    "def extract_all_image_names(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    all_image_names = []\n",
    "    \n",
    "    # Iterate through all subjects\n",
    "    for subject_id, subject_data in data.items():\n",
    "        image_names = [key for key in subject_data if key.endswith(\".JPG\")]\n",
    "        if image_names:\n",
    "            for imahe in image_names:\n",
    "                all_image_names.append(imahe)\n",
    "\n",
    "    \n",
    "    return all_image_names\n",
    "\n",
    "# Extract image names from all subjects\n",
    "all_images = extract_all_image_names(json_file_path)\n",
    "\n",
    "\n",
    "extracted_images = [all_images[i - 1] for i in indices_to_extract]\n",
    "\n",
    "print(extracted_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the ReLU function\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Define the Softmax function\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))  # Stability improvement: subtract max(x) for numerical stability\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# Generate input values\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "relu_values = relu(x)\n",
    "\n",
    "\n",
    "plt.plot(x, relu_values, label='ReLU')\n",
    "# plt.title(\"ReLU Activation Function\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.grid(True, color='gray', alpha=0.35)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Generate a range of values for the input (logits)\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "# Apply the Softmax function\n",
    "softmax_values = softmax(x)\n",
    "\n",
    "# Plot the Softmax function\n",
    "plt.plot(x, softmax_values, label=\"Softmax\")\n",
    "# plt.title(\"Softmax Activation Function\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.legend()\n",
    "plt.grid(True, color='gray', alpha=0.35)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
